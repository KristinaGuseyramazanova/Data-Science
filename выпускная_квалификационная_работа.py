# -*- coding: utf-8 -*-
"""Выпускная квалификационная работа

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pmCvVKCD9toTcWiaGMBBrqv78airZvcM
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

"""# **1. Загрузка данных**"""

from google.colab import drive
drive.mount('/content/drive')

#Загружаем данные из exlcel, уберём колонку с индексом
X_bp_data = pd.read_excel('/content/drive/MyDrive/X_bp.xlsx', index_col=0)
X_nup_data = pd.read_excel('/content/drive/MyDrive/X_nup.xlsx', index_col=0)

#Преобразуем в DataFrame для дальнейшего использования
X_bp_data_df = pd.DataFrame(X_bp_data)
X_nup_data_df = pd.DataFrame(X_nup_data)

# Для удобства выведим в одну строчку
print (X_bp_data_df.head(5).to_string())

print(df.head(5).to_string())

print (X_bp_data_df.shape, X_nup_data_df.shape)#После объединения таблиц должны получить размерность (1023, 13)

#Объединение по индексу, тип объединения INNER
df = X_bp_data_df.merge(X_nup_data_df, how='inner', left_index = True, right_index = True)

#Посмотрим размерность полученного DS
print(df.shape)

#Посмотрим с каким типом переменных нам предстоит работать.
#Все переменные являются количественными (тип float), признаков с типом "object" нет - значит нет строковых значений.
df.info()

# Проверяем на пропуски
# Пропусков нет
df.isnull().sum()

# Количество уникальных значений в каждом столбце
df.nunique()

# Посмотрим описательную статистику
df.describe().T

"""Мы видим количество наблюдений (count), среднее арифметическое (mean), среднее квадратическое отклонение (std), минимальное (min) и максимальное (max) значения, а также первый (25%), второй (50%) и третий (75%) квартиль (второй квартиль это то же самое, что медиана) каждой количественной переменной.

# **2. Исследовательский анализ данных**
Выполним исследовательский или разведочный анализ данных (Exploratory Data Analysis, EDA)

Сильная корреляция, когда значение приближается к 1 или −1, и ее отсутствии, когда значение близко к нулю.
"""

df.columns

# Построю графики распределения переменных и "ящики с усами"
#Все признаки, кроме "Угол нашивки, град" имеют нормальное распределение. Они количественные, вещественные. Принимают неотрицательные значения.
#"Угол нашивки, град" принимает 2 значения. Можно превратить в бинарный признак.
fig, axes = plt.subplots(13, 2, figsize=(13, 48))
for k, column in enumerate(df.columns):
    sns.histplot(data=df, x=column, kde=True, ax=axes[k, 0])
    sns.boxplot(data=df, x=column, ax=axes[k, 1])
plt.show()

#Отобразим тепловую карту Пирсона
fig = plt.figure(figsize = (10,10))
sns.heatmap(df.corr(), annot = True, vmin=-0.02, vmax=0.2, center= -0.4)

#Построим график рассеяния
#видно, что выбросы есть. Некоторые точки стоят очень далеко от общего облака.
sns.pairplot(df, height=2)

"""# **Очистим данные от выбросов**"""

#Воспользуемся методом перцентиля (numpy.percentile)
for col in df.columns:
    q25,q75 = np.percentile(df.loc[:,col],[25,75])
    iqr = q75-q25
    min = q25-(1.5*iqr)
    max = q75+(1.5*iqr)

#Заменяем нулевыми значениями
    df.loc[df[col] < min,col] = np.nan
    df.loc[df[col] > max,col] = np.nan

#Смотрим результат
df.isnull().sum()

#Удаляем нулевые значения
df = df.dropna(axis = 0)
#Результат
df.isnull().sum()

df.info()

df.describe()

"""# **Нормализуем данные**"""

# Нормальзуем значения с помощью метода MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

min_max_scaler = MinMaxScaler()
df_norm = pd.DataFrame(min_max_scaler.fit_transform(df), columns = df.columns, index=df.index)
df_norm.describe()

df_norm.head()

"""# **Графики после нормализации и исключения выбросов**"""

fig, axes = plt.subplots(13, 2, figsize=(13, 48))
for k, column in enumerate(df_norm.columns):
    sns.histplot(data=df, x=column, kde=True, ax=axes[k, 0])
    sns.boxplot(data=df, x=column, ax=axes[k, 1])
plt.show()

"""# **Корреляционная тепловая карта Пирсона после нормализации и исключения выбросов**"""

fig = plt.figure(figsize = (10,10))
sns.heatmap(df_norm.corr(), annot = True, vmin=-0.02, vmax=0.2, center= -0.4)

"""# **Попарные графики рассеяния точек после нормализации и исключения выбросов**"""

sns.pairplot(df_norm, height=3)

"""# **Обучение моделей для прогноза модуля упругости при растяжении и прочности при растяжении**

*  Провести предобработку данных.
*  Обучить нескольких моделей для прогноза модуля упругости при растяжении и прочности при растяжении.
*  30% данных оставить на тестирование модели, на остальных происходит обучение моделей.
*   При построении моделей провести поиск гиперпараметров модели с помощью поиска по сетке с перекрестной проверкой, количество блоков равно 10.
*   Написать нейронную сеть, которая будет рекомендовать соотношение матрица-наполнитель.
"""

#Построение моделей для прогноза модуля упругости при растяжении и прочности при растяжении
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression # SGDRegressor
#from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

#Разбиваем данные на обучающую и тестовую выборки
x_mod = df.drop(['Модуль упругости при растяжении, ГПа'], axis=1)
x_pr = df.drop(['Прочность при растяжении, МПа'], axis=1)
y_mod = df[['Модуль упругости при растяжении, ГПа']]
y_pr = df[['Прочность при растяжении, МПа']]

X_train_mod, X_test_mod, y_train_mod, y_test_mod = train_test_split(x_mod, y_mod, test_size=0.3, random_state=42)
X_train_pr, X_test_pr, y_train_pr, y_test_pr = train_test_split(x_pr, y_pr, test_size=0.3, random_state=42)

"""# **Строим модели**
# **KNeighborsRegressor**
"""

scoring = ['r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error']
cv_knn = KFold(10, shuffle=True)
params_knn = {'n_neighbors' : range(1, 301, 2),
          'weights' : ['uniform', 'distance'],
          'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']
          }
model_knn=KNeighborsRegressor(n_neighbors=10)
GSCV_knn = GridSearchCV(model_knn, params_knn, n_jobs=-1, cv=cv_knn)

"""Для пронгоза модуля упругости при растяжении"""

GSCV_knn.fit(X_train_mod,y_train_mod)
y_pred_mod = GSCV_knn.predict(X_test_mod)
model_mae_knn_mod = mean_absolute_error(y_test_mod, y_pred_mod)
model_r2_knn_mod = r2_score(y_test_mod, y_pred_mod)
model_rmse_knn_mod = mean_squared_error(y_test_mod, y_pred_mod, squared=False)
print(GSCV_knn.best_params_)
print(GSCV_knn.best_estimator_)
print(GSCV_knn.best_score_)
print('K-neighbors MAE:',model_mae_knn_mod)
print('K-neighbors R2:',model_r2_knn_mod)
print('K-neighbors RMSE:',model_rmse_knn_mod)

"""Для прогноза прочности при растяжении"""

GSCV_knn.fit(X_train_pr,y_train_pr)
y_pred_pr = GSCV_knn.predict(X_test_pr)
model_mae_knn_pr = mean_absolute_error(y_test_pr, y_pred_pr)
model_r2_knn_pr = r2_score(y_test_pr, y_pred_pr)
model_rmse_knn_pr = mean_squared_error(y_test_pr, y_pred_pr, squared=False)
print(GSCV_knn.best_params_)
print(GSCV_knn.best_estimator_)
print(GSCV_knn.best_score_)
print('K-neighbors MAE:',model_mae_knn_pr)
print('K-neighbors R2:',model_r2_knn_pr)
print('K-neighbors RMSE:',model_rmse_knn_pr)

# Проведем поиск  по сетке гиперпараметров с перекрестной проверкой, количество блоков равно 10 (cv = 10)
# Метода К ближайших соседей  KNeighbors Regressor
knn = KNeighborsRegressor()
knn_params = {'n_neighbors' : range(1, 201, 2),
          'weights' : ['uniform', 'distance'],
          'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']
          }
#Запустим обучение модели. В качестве оценки модели будем использовать коэффициент детерминации (R^2)
# Если R2<0, это значит, что разработанная модель даёт прогноз даже хуже, чем простое усреднение.
GSCV_knn = GridSearchCV(knn, knn_params, cv = 10, verbose = 1, n_jobs=-1, scoring = 'r2')
GSCV_knn.fit(X_train_pr,y_train_pr)
knn = GSCV_knn.best_estimator_
GSCV_knn.best_params_

"""# **GradientBoostingRegressor**"""

model_gb=GradientBoostingRegressor()

"""Для пронгоза модуля упругости при растяжении"""

model_gb.fit(X_train_mod,np.ravel(y_train_mod))
y_pred_mod = model_gb.predict(X_test_mod)
model_mae_gb_mod = mean_absolute_error(y_test_mod, y_pred_mod)
model_r2_gb_mod = r2_score(y_test_mod, y_pred_mod)
model_rmse_gb_mod = mean_squared_error(y_test_mod, y_pred_mod, squared=False)
print('Gradient Boosting MAE:',model_mae_gb_mod)
print('Gradient Boosting R2:',model_r2_gb_mod)
print('Gradient Boosting RMSE:',model_rmse_gb_mod)

"""Для прогноза прочности при растяжении"""

model_gb.fit(X_train_pr,np.ravel(y_train_pr))
y_pred_pr = model_gb.predict(X_test_pr)
model_mae_gb_pr = mean_absolute_error(y_test_pr, y_pred_pr)
model_r2_gb_pr = r2_score(y_test_pr, y_pred_pr)
model_rmse_gb_pr = mean_squared_error(y_test_pr, y_pred_pr, squared=False)
print('Gradient Boosting MAE:',model_mae_gb_pr)
print('Gradient Boosting R2:',model_r2_gb_pr)
print('Gradient Boosting RMSE:',model_rmse_gb_pr)

# ИСПРАВИТЬ !!!!! model_gb=GradientBoostingRegressor()
model_gb = GridSearchCV(knn, knn_params, cv = 10, verbose = 1, n_jobs=-1, scoring = 'r2')
model_gb.fit(X_train_pr,y_train_pr)
model_gb = GSCV_knn.best_estimator_
model_gb.best_params_

"""# **LinearRegression**"""

model_lr=LinearRegression()

"""Для пронгоза модуля упругости при растяжении"""

model_lr.fit(X_train_mod,y_train_mod)
y_pred_mod = model_lr.predict(X_test_mod)
model_mae_lr_mod = mean_absolute_error(y_test_mod, y_pred_mod)
model_r2_lr_mod = r2_score(y_test_mod, y_pred_mod)
model_rmse_lr_mod = mean_squared_error(y_test_mod, y_pred_mod, squared=False)
print('Random Forest MAE:',model_mae_lr_mod)
print('Random Forest R2:',model_r2_lr_mod)
print('Random Forest RMSE:',model_rmse_lr_mod)

"""Для прогноза прочности при растяжении"""

model_lr.fit(X_train_pr,y_train_pr)
y_pred_pr = model_lr.predict(X_test_pr)
model_mae_lr_pr = mean_absolute_error(y_test_pr, y_pred_pr)
model_r2_lr_pr = r2_score(y_test_pr, y_pred_pr)
model_rmse_lr_pr = mean_squared_error(y_test_pr, y_pred_pr, squared=False)
print('Random Forest MAE:',model_mae_lr_pr)
print('Random Forest R2:',model_r2_lr_pr)
print('Random Forest RMSE:',model_rmse_lr_pr)

#ДОПИСАТЬ

"""# **RandomForestRegressor**"""

model_rf=RandomForestRegressor()

"""Для пронгоза модуля упругости при растяжении"""

model_rf.fit(X_train_mod,y_train_mod)
y_pred_mod = model_rf.predict(X_test_mod)
model_mae_rf_mod = mean_absolute_error(y_test_mod, y_pred_mod)
model_r2_rf_mod = r2_score(y_test_mod, y_pred_mod)
model_rmse_rf_mod = mean_squared_error(y_test_mod, y_pred_mod, squared=False)
print('Random Forest MAE:',model_mae_rf_mod)
print('Random Forest R2:',model_r2_rf_mod)
print('Random Forest RMSE:',model_rmse_rf_mod)

"""Для прогноза прочности при растяжении"""

model_rf.fit(X_train_pr,y_train_pr)
y_pred_pr = model_rf.predict(X_test_pr)
model_mae_rf_pr = mean_absolute_error(y_test_pr, y_pred_pr)
model_r2_rf_pr = r2_score(y_test_pr, y_pred_pr)
model_rmse_rf_pr = mean_squared_error(y_test_pr, y_pred_pr, squared=False)
print('Random Forest MAE:',model_mae_rf_pr)
print('Random Forest R2:',model_r2_rf_pr)
print('Random Forest RMSE:',model_rmse_rf_pr)

#ИСПРАВИТЬ !!!!!!!# Проведем поиск  по сетке гиперпараметров с перекрестной проверкой, количество блоков равно 10 (cv = 10)
# модели случайного леса  Random Forest Regressor
rfr = RandomForestRegressor()
rfr_params = {
    'n_estimators' : range(10, 500, 10),
    'criterion' : ['squared_error', 'absolute_error', 'poisson'],
    'max_depth' : range(1, 7),
    'min_samples_split' : range(20, 50, 5),
    'min_samples_leaf' : range(2, 8),
    'bootstrap' : ['True', 'False']
}
model_rf = RandomizedSearchCV(rfr, rfr_params, n_jobs=-1, cv=10, verbose=4)
parametrs = { 'n_estimators': [200, 300],
              'max_depth': [9, 15],
              'max_features': ['auto'],
              'criterion': ['mse'] }
grid21 = GridSearchCV(estimator = rfr, param_grid  = parametrs, cv=10)
grid21.fit(X_train_pr, y_train_pr)

models = pd.DataFrame()
knn_mod = pd.DataFrame({
   'Model': 'KNeighborsRegressor_mod',
   'MAE': model_mae_knn_mod,
   'R2 score': model_r2_knn_mod,
   'RMSE': model_rmse_knn_mod
}, index=['Модуль упругости при растяжении'])
gb_mod = pd.DataFrame({
   'Model': 'GradientBoostingRegressor_mod',
   'MAE': model_mae_gb_mod,
   'R2 score': model_r2_gb_mod,
   'RMSE': model_rmse_gb_mod
}, index=['Модуль упругости при растяжении'])
rf_mod = pd.DataFrame({
   'Model': 'RandomForestRegressor_mod',
   'MAE': model_mae_rf_mod,
   'R2 score': model_r2_rf_mod,
   'RMSE': model_rmse_rf_mod
}, index=['Модуль упругости при растяжении'])
lr_mod = pd.DataFrame({
   'Model': 'LinearRegression_mod',
   'MAE': model_mae_lr_mod,
   'R2 score': model_r2_lr_mod,
   'RMSE': model_rmse_lr_mod
}, index=['Модуль упругости при растяжении'])
knn_pr = pd.DataFrame({
   'Model': 'KNeighborsRegressor_pr',
   'MAE': model_mae_knn_pr,
   'R2 score': model_r2_knn_pr,
   'RMSE': model_rmse_knn_pr
}, index=['Прочность при растяжении'])
gb_pr = pd.DataFrame({
   'Model': 'GradientBoostingRegressor_pr',
   'MAE': model_mae_gb_pr,
   'R2 score': model_r2_gb_pr,
   'RMSE': model_rmse_gb_pr
}, index=['Прочность при растяжении'])
rf_pr = pd.DataFrame({
   'Model': 'RandomForestRegressor_mod',
   'MAE': model_mae_rf_pr,
   'R2 score': model_r2_rf_pr,
   'RMSE': model_rmse_rf_pr
}, index=['Прочность при растяжении'])
lr_pr = pd.DataFrame({
   'Model': 'LinearRegression_mod',
   'MAE': model_mae_lr_pr,
   'R2 score': model_r2_lr_pr,
   'RMSE': model_rmse_lr_pr
}, index=['Прочность при растяжении'])

models = pd.concat([models, knn_mod, gb_mod, rf_mod, lr_mod, knn_pr, gb_pr, rf_pr, lr_pr])

models_s= models.sort_values(by=['MAE', 'R2 score', 'RMSE'])
models_s

sns.catplot(data=models_s[0:4], x='Model', y='MAE', kind='bar', height=6, aspect=2)
plt.xticks(size=12)
plt.title('Средняя абсолютная ошибка МАЕ моделей прогноза для модуля упругости при растяжении', size=7)

sns.catplot(data=models_s[4:9], x='Model', y='MAE', kind='bar', height=6, aspect=2)
plt.xticks(size=12)
plt.title('Средняя абсолютная ошибка МАЕ моделей прогноза для прочности при растяжении', size=7)

sns.catplot(data=models_sort[0:4], x='Model', y='R2 score', kind='bar', height=6, aspect=2)
plt.ylim(ymin=-0.15, ymax=0.1)
plt.xticks(size=12)
plt.title('Коэффициент детерминации R2 моделей прогноза для модуля упругости при растяжении', size=7)

sns.catplot(data=models_sort[4:9], x='Model', y='R2 score', kind='bar', height=6, aspect=2)
plt.xticks(size=12)
plt.title('Коэффициент детерминации R2 моделей прогноза для модуля упругости при растяжении', size=7)

sns.catplot(data=models_sort[0:4], x='Model', y='RMSE', kind='bar', height=6, aspect=2)
plt.xticks(size=12)
plt.title('Средняя квадратичная ошибка RMSE моделей прогноза для модуля упругости при растяжении', size=7)

sns.catplot(data=models_sort[4:9], x='Model', y='RMSE', kind='bar', height=6, aspect=2)
plt.xticks(size=12)
plt.title('Средняя квадратичная ошибка RMSE моделей прогноза для модуля упругости при растяжении', size=7)

"""Судя по полученым данным наши модели не подходят для предсказания."""













"""# **Пишем нейронную сеть на Keras.tensorflow для рекомендаций соотношение матрица-наполнитель**"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential, utils, layers
from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Activation, Dropout, LSTM
import tensorflow.python.keras.optimizers

#разбиваем данные
x = df.drop(['Соотношение матрица-наполнитель'], axis=1)
y = df[['Соотношение матрица-наполнитель']]

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)
normalizer = tf.keras.layers.Normalization(axis=-1)
X_train_norm = normalizer.adapt(np.array(X_train))

"""# **Нейронная сеть**"""

model = Sequential(X_train_norm)
model.add(Dense(128))
model.add(BatchNormalization())
model.add(LeakyReLU())
model.add(Dense(128, activation='selu'))
model.add(BatchNormalization())
model.add(Dense(64, activation='selu'))
model.add(BatchNormalization())
model.add(Dense(32, activation='selu'))
model.add(BatchNormalization())
model.add(LeakyReLU())
model.add(Dense(16, activation='selu'))
model.add(BatchNormalization())
model.add(Dense(1))
model.add(Activation('selu'))

model.compile(loss = 'mean_absolute_error', optimizer=tf.optimizers.SGD(learning_rate=0.01))

history = model.fit(X_train, y_train, batch_size = 32, epochs = 200, validation_data = (X_train, y_train), verbose = 1, validation_split = 0.2)

model.summary()

plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('График потерь', size=12)
plt.ylabel('Средняя абсолютная ошибка', size=12)
plt.xlabel('Эпоха', size=12)
plt.legend(['loss', 'val_loss'], loc='best')
plt.show()

y_pred=model.predict(np.array(X_test))

plt.figure(figsize=(10,5))
plt.title('Тестовые и прогнозные значения', size=12)
plt.plot(y_test.values, color='blue', label = 'Тестовые значения')
plt.plot(y_pred, color='red', label = 'Прогнозные значения')
plt.legend(loc='best')
plt.show()

mae_n = mean_absolute_error(y_test, y_pred)
print('MAE:',mae_n)